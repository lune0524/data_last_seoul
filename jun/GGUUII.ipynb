{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6d7db10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import ttk\n",
    "from tkinter.scrolledtext import ScrolledText\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "# -------------------- ì „ì²˜ë¦¬ í•¨ìˆ˜ --------------------\n",
    "def normalize_station(name: str) -> str:\n",
    "    name = str(name)\n",
    "    name = re.sub(r\"\\(.*?\\)\", \"\", name).strip()\n",
    "    return name if name.endswith(\"ì—­\") else name + \"ì—­\"\n",
    "\n",
    "# -------------------- í•µì‹¬ ê³„ì‚° í•¨ìˆ˜ --------------------\n",
    "def calculate_recommendations():\n",
    "    yearly_files = {\n",
    "        2020: \"ì„œìš¸êµí†µê³µì‚¬_ì—­ë³„ ì‹œê°„ëŒ€ë³„ ìŠ¹í•˜ì°¨ì¸ì›(20.1~20.12).csv\",\n",
    "        2021: \"ì„œìš¸êµí†µê³µì‚¬_ì—­ë³„ ì‹œê°„ëŒ€ë³„ ìŠ¹í•˜ì°¨ì¸ì›(21.1~21.12).csv\",\n",
    "        2022: \"ì„œìš¸êµí†µê³µì‚¬_ì—­ë³„ ì‹œê°„ëŒ€ë³„ ìŠ¹í•˜ì°¨ì¸ì›(22.1~22.12).csv\",\n",
    "        2023: \"ì„œìš¸êµí†µê³µì‚¬_ì—­ë³„ ì‹œê°„ëŒ€ë³„ ìŠ¹í•˜ì°¨ì¸ì›(23.1~23.12).csv\",\n",
    "        2024: \"ì„œìš¸êµí†µê³µì‚¬_ì—­ë³„ ì‹œê°„ëŒ€ë³„ ìŠ¹í•˜ì°¨ì¸ì›(24.1~24.12).csv\",\n",
    "    }\n",
    "\n",
    "    daily_all = []\n",
    "    for year, path in yearly_files.items():\n",
    "        df = pd.read_csv(path, encoding=\"cp949\", low_memory=False)\n",
    "        a_col = [c for c in df.columns if \"êµ¬ë¶„\" in c][0]\n",
    "        date_col = [c for c in df.columns if \"ì‚¬ìš©ì¼ì\" in c or \"ì¼ì\" in c]\n",
    "        days = 366 if year % 4 == 0 else 365\n",
    "        if date_col:\n",
    "            df[date_col[0]] = pd.to_datetime(df[date_col[0]], errors=\"coerce\")\n",
    "            days = df[date_col[0]].dt.normalize().nunique()\n",
    "\n",
    "        ride_df = df[df[a_col] == \"ìŠ¹ì°¨\"].copy()\n",
    "        exit_df = df[df[a_col] == \"í•˜ì°¨\"].copy()\n",
    "        time_cols = [c for c in df.columns if (\"~\" in c or \"ì‹œ\" in c) and \"ìŠ¹ê°•\" not in c]\n",
    "        ride_df[time_cols] = ride_df[time_cols].apply(pd.to_numeric, errors=\"coerce\")\n",
    "        exit_df[time_cols] = exit_df[time_cols].apply(pd.to_numeric, errors=\"coerce\")\n",
    "        total = ride_df.groupby(\"ì—­ëª…\")[time_cols].sum().sum(axis=1) + \\\n",
    "                exit_df.groupby(\"ì—­ëª…\")[time_cols].sum().sum(axis=1)\n",
    "        daily = (total / days).reset_index(name=\"ì¼í‰ê· ì´ìš©ê°\")\n",
    "        daily[\"ì •ê·œì—­ëª…\"] = daily[\"ì—­ëª…\"].apply(normalize_station)\n",
    "        daily_all.append(daily[[\"ì •ê·œì—­ëª…\", \"ì¼í‰ê· ì´ìš©ê°\"]])\n",
    "\n",
    "    daily_df = pd.concat(daily_all, ignore_index=True)\n",
    "    avg_pop = daily_df.groupby(\"ì •ê·œì—­ëª…\")[\"ì¼í‰ê· ì´ìš©ê°\"].mean().reset_index(name=\"í‰ê· ìœ ë™ì¸êµ¬\")\n",
    "\n",
    "    accident_df = pd.read_csv(\"ì„œìš¸êµí†µê³µì‚¬_ìµœê·¼ 5ë…„ ì§€í•˜ì²  ì‚¬ê³  í˜„í™©_20250310.csv\", encoding=\"cp949\")\n",
    "    accident_df[\"ì •ê·œì—­ëª…\"] = accident_df[\"ë°œìƒì—­\"].apply(normalize_station)\n",
    "\n",
    "    ext_df = pd.read_csv(\"ì„œìš¸êµí†µê³µì‚¬_ì†Œí™”ê¸°ì„¤ì¹˜í˜„í™©_20250310.csv\", encoding=\"cp949\")\n",
    "    ext_df[\"ì •ê·œì—­ëª…\"] = ext_df[\"ì—­ëª…\"].apply(normalize_station)\n",
    "    ext_qty_col = [c for c in ext_df.columns if \"ë³´ìœ \" in c or \"ìˆ˜\" in c][0]\n",
    "    ext_cnt = ext_df.groupby(\"ì •ê·œì—­ëª…\")[ext_qty_col].sum().reset_index(name=\"ì†Œí™”ê¸°ìˆ˜\")\n",
    "\n",
    "    mask_df = pd.read_csv(\"ì„œìš¸êµí†µê³µì‚¬_ì—­ë³„ í™”ì¬ìš© ëŒ€í”¼ë§ˆìŠ¤í¬ í˜„í™©_20250310.csv\", encoding=\"cp949\")\n",
    "    mask_df[\"ì •ê·œì—­ëª…\"] = mask_df[\"ì—­ëª…\"].apply(normalize_station)\n",
    "    mask_qty_col = [c for c in mask_df.columns if \"ë³´ìœ \" in c or \"ìˆ˜\" in c][0]\n",
    "    mask_cnt = mask_df.groupby(\"ì •ê·œì—­ëª…\")[mask_qty_col].sum().reset_index(name=\"ëŒ€í”¼ë§ˆìŠ¤í¬ìˆ˜\")\n",
    "\n",
    "    arch_df = pd.read_csv(\"ì„œìš¸êµí†µê³µì‚¬_ì—­ì‚¬ê±´ì¶•ì •ë³´_20250310.csv\", encoding=\"cp949\")\n",
    "    arch_df[\"ì •ê·œì—­ëª…\"] = arch_df[\"ì—­ëª…\"].apply(normalize_station)\n",
    "    arch_area = arch_df.groupby(\"ì •ê·œì—­ëª…\")[\"ë©´ì \"].sum().reset_index(name=\"ì—­ë©´ì \")\n",
    "\n",
    "    accident_weights = {\n",
    "        \"ì¶œì…ë¬¸ê´€ë ¨\": {\"weight\": 1.3, \"action\": \"ì¶œì…ë¬¸ ì„¼ì„œ ì ê²€ ë° ìŠ¹í•˜ì°¨ ìœ ë„ì„  ì •ë¹„\"},\n",
    "        \"ì—­êµ¬ë‚´ ì‚¬ê³ \": {\"weight\": 1.2, \"action\": \"ê³„ë‹¨ ë¯¸ë„ëŸ¼ ë°©ì§€ íŒ¨ë“œ ì„¤ì¹˜, ì•ˆë‚´íŒ ë³´ê°•\"},\n",
    "        \"ì—´ì°¨ë‚´ ì‚¬ê³ \": {\"weight\": 1.1, \"action\": \"ì°¨ë‚´ ì•ˆë‚´ë°©ì†¡ ê°œì„  ë° ì†ì¡ì´ ì •ë¹„\"},\n",
    "        \"ë°œë¹ ì§\": {\"weight\": 1.4, \"action\": \"ìŠ¹ê°•ì¥ í‹ˆìƒˆ ë°©ì§€ ì„¤ë¹„ ì¶”ê°€\"},\n",
    "        \"ìŠ¹ê°•ì„¤ë¹„ê´€ë ¨\": {\"weight\": 1.5, \"action\": \"ì—˜ë¦¬ë² ì´í„°/ì—ìŠ¤ì»¬ë ˆì´í„° ì •ê¸° ì ê²€ ê°•í™”\"},\n",
    "        \"ê¸°íƒ€\": {\"weight\": 0.8, \"action\": \"CCTV ë° ë¹„ìƒë²¨ ì„¤ì¹˜ í™•ëŒ€\"},\n",
    "    }\n",
    "\n",
    "    summary = accident_df.groupby([\"ì •ê·œì—­ëª…\", \"ì‚¬ê³ ìœ í˜•\"]).size().unstack(fill_value=0)\n",
    "    summary[\"ì‚¬ê³ ê±´ìˆ˜\"] = summary.sum(axis=1)\n",
    "    for t, meta in accident_weights.items():\n",
    "        summary[f\"{t}_ì ìˆ˜\"] = summary.get(t, 0) * meta[\"weight\"]\n",
    "    summary[\"ì‚¬ê³ ìœ í˜•ì ìˆ˜í•©\"] = summary[[f\"{t}_ì ìˆ˜\" for t in accident_weights]].sum(axis=1)\n",
    "\n",
    "    summary = summary.reset_index()\n",
    "    summary = summary.merge(avg_pop, on=\"ì •ê·œì—­ëª…\", how=\"left\")\n",
    "    summary = summary.merge(arch_area, on=\"ì •ê·œì—­ëª…\", how=\"left\")\n",
    "    summary = summary.merge(ext_cnt, on=\"ì •ê·œì—­ëª…\", how=\"left\")\n",
    "    summary = summary.merge(mask_cnt, on=\"ì •ê·œì—­ëª…\", how=\"left\")\n",
    "    summary = summary.set_index(\"ì •ê·œì—­ëª…\")\n",
    "\n",
    "    summary[\"ìœ ë™ì¸êµ¬ë°€ë„\"] = summary[\"í‰ê· ìœ ë™ì¸êµ¬\"] / summary[\"ì—­ë©´ì \"]\n",
    "    summary[\"ì†Œí™”ê¸°ë°€ë„\"] = summary[\"ì†Œí™”ê¸°ìˆ˜\"] / summary[\"ì—­ë©´ì \"]\n",
    "    summary[\"ë§ˆìŠ¤í¬ì¸êµ¬ë¹„\"] = summary[\"ëŒ€í”¼ë§ˆìŠ¤í¬ìˆ˜\"] / summary[\"í‰ê· ìœ ë™ì¸êµ¬\"]\n",
    "\n",
    "    ext_density_med = summary[\"ì†Œí™”ê¸°ë°€ë„\"].median()\n",
    "    mask_ratio_med = summary[\"ë§ˆìŠ¤í¬ì¸êµ¬ë¹„\"].median()\n",
    "\n",
    "    global type_ratio\n",
    "    type_ratio = summary[[k for k in accident_weights]].div(summary[\"ì‚¬ê³ ê±´ìˆ˜\"], axis=0)\n",
    "\n",
    "    def recommend(row):\n",
    "        actions, reasons = set(), []\n",
    "        for t in type_ratio.loc[row.name].sort_values(ascending=False).head(2).index:\n",
    "            actions.add(accident_weights[t][\"action\"])\n",
    "            reasons.append(f\"{t} ì‚¬ê³  ë¹„ìœ¨ì´ ë†’ìŒ\")\n",
    "        if pd.notna(row[\"ìœ ë™ì¸êµ¬ë°€ë„\"]) and row[\"ìœ ë™ì¸êµ¬ë°€ë„\"] > summary[\"ìœ ë™ì¸êµ¬ë°€ë„\"].quantile(0.8):\n",
    "            actions.add(\"ì—­ ë‚´ ìœ ë™ ë™ì„  ì¬ë°°ì¹˜ ë˜ëŠ” í™•ì¥\")\n",
    "            reasons.append(\"ì—­ í¬ê¸°ì— ë¹„í•´ ìœ ë™ì¸êµ¬ê°€ ë§ìŒ\")\n",
    "        if pd.notna(row[\"ì†Œí™”ê¸°ë°€ë„\"]) and row[\"ì†Œí™”ê¸°ë°€ë„\"] < ext_density_med:\n",
    "            actions.add(\"ì†Œí™”ê¸° ì¶”ê°€ ì„¤ì¹˜\")\n",
    "            reasons.append(\"ì†Œí™”ê¸° ë°€ë„ê°€ ë‚®ìŒ\")\n",
    "        if pd.notna(row[\"ë§ˆìŠ¤í¬ì¸êµ¬ë¹„\"]) and row[\"ë§ˆìŠ¤í¬ì¸êµ¬ë¹„\"] < mask_ratio_med:\n",
    "            actions.add(\"ëŒ€í”¼ë§ˆìŠ¤í¬ ë¹„ì¹˜ í™•ëŒ€\")\n",
    "            reasons.append(\"ìœ ë™ì¸êµ¬ ëŒ€ë¹„ ëŒ€í”¼ë§ˆìŠ¤í¬ ë¶€ì¡±\")\n",
    "        return \" + \".join(actions), \" / \".join(reasons)\n",
    "\n",
    "    recommendations = summary.apply(lambda r: recommend(r), axis=1, result_type=\"expand\")\n",
    "    recommendations.columns = [\"ì¶”ì²œ ë³´ìˆ˜ ì¡°ì¹˜\", \"ì¶”ì²œ ì´ìœ \"]\n",
    "    top20_accidents = summary.sort_values(\"ì‚¬ê³ ê±´ìˆ˜\", ascending=False).head(20)[[\"ì‚¬ê³ ê±´ìˆ˜\"]]\n",
    "    return recommendations, top20_accidents, sorted(recommendations.index.tolist()), summary\n",
    "\n",
    "# -------------------- ë°ì´í„° ê³„ì‚° --------------------\n",
    "recommend_df, top20_df, station_names, summary = calculate_recommendations()\n",
    "\n",
    "# -------------------- GUI í•¨ìˆ˜ --------------------\n",
    "def update_output(text):\n",
    "    output_text.config(state=\"normal\")\n",
    "    output_text.delete(\"1.0\", tk.END)\n",
    "    output_text.insert(tk.END, text)\n",
    "    output_text.config(state=\"disabled\")\n",
    "\n",
    "def search_station():\n",
    "    query = entry.get().strip()\n",
    "    if not query.endswith(\"ì—­\"):\n",
    "        query += \"ì—­\"\n",
    "\n",
    "    if query in recommend_df.index:\n",
    "        result = recommend_df.loc[query]\n",
    "        row = summary.loc[query]\n",
    "\n",
    "        ratio_row = type_ratio.loc[query]\n",
    "        ratio_str = \"\\n\".join(f\"{col}: {val:.1%}\" for col, val in ratio_row.items() if val > 0)\n",
    "        acc_cnt   = f\"{int(row['ì‚¬ê³ ê±´ìˆ˜'])}\" if pd.notna(row['ì‚¬ê³ ê±´ìˆ˜']) else \"ì •ë³´ ì—†ìŒ\"\n",
    "\n",
    "        pop = f\"{row['í‰ê· ìœ ë™ì¸êµ¬']:.0f}\" if pd.notna(row['í‰ê· ìœ ë™ì¸êµ¬']) else \"ì •ë³´ ì—†ìŒ\"\n",
    "        area = f\"{row['ì—­ë©´ì ']:.2f}\" if pd.notna(row['ì—­ë©´ì ']) else \"ì •ë³´ ì—†ìŒ\"\n",
    "        density = f\"{row['ìœ ë™ì¸êµ¬ë°€ë„']:.3f}\" if pd.notna(row['ìœ ë™ì¸êµ¬ë°€ë„']) else \"ì •ë³´ ì—†ìŒ\"\n",
    "\n",
    "        rank_acc  = summary['ì‚¬ê³ ê±´ìˆ˜'].rank(ascending=False, method='min')   # âŠ\n",
    "\n",
    "        ext_cnt = f\"{int(row['ì†Œí™”ê¸°ìˆ˜'])}\" if pd.notna(row['ì†Œí™”ê¸°ìˆ˜']) else \"ì •ë³´ ì—†ìŒ\"\n",
    "        ext_density = f\"{row['ì†Œí™”ê¸°ë°€ë„']:.5f}\" if pd.notna(row['ì†Œí™”ê¸°ë°€ë„']) else \"ì •ë³´ ì—†ìŒ\"\n",
    "        mask_cnt = f\"{int(row['ëŒ€í”¼ë§ˆìŠ¤í¬ìˆ˜'])}\" if pd.notna(row['ëŒ€í”¼ë§ˆìŠ¤í¬ìˆ˜']) else \"ì •ë³´ ì—†ìŒ\"\n",
    "        mask_ratio = f\"{row['ë§ˆìŠ¤í¬ì¸êµ¬ë¹„']:.5f}\" if pd.notna(row['ë§ˆìŠ¤í¬ì¸êµ¬ë¹„']) else \"ì •ë³´ ì—†ìŒ\"\n",
    "\n",
    "        rank_pop = summary['ìœ ë™ì¸êµ¬ë°€ë„'].rank(ascending=False, method='min')\n",
    "        rank_ext = summary['ì†Œí™”ê¸°ë°€ë„'].rank(ascending=False, method='min')\n",
    "        rank_mask = summary['ë§ˆìŠ¤í¬ì¸êµ¬ë¹„'].rank(ascending=False, method='min')\n",
    "\n",
    "        pop_rank_str  = f\"{int(rank_pop[query])}ìœ„ / {int(rank_pop.count())}ê°œ ì—­\"  if pd.notna(row['ìœ ë™ì¸êµ¬ë°€ë„']) else \"ì •ë³´ ì—†ìŒ\"\n",
    "        ext_rank_str  = f\"{int(rank_ext[query])}ìœ„ / {int(rank_ext.count())}ê°œ ì—­\"  if pd.notna(row['ì†Œí™”ê¸°ë°€ë„'])  else \"ì •ë³´ ì—†ìŒ\"\n",
    "        mask_rank_str = f\"{int(rank_mask[query])}ìœ„ / {int(rank_mask.count())}ê°œ ì—­\" if pd.notna(row['ë§ˆìŠ¤í¬ì¸êµ¬ë¹„']) else \"ì •ë³´ ì—†ìŒ\"\n",
    "        acc_rank  = f\"{int(rank_acc[query])}ìœ„ / {int(rank_acc.count())}ê°œ ì—­\" \\\n",
    "           if pd.notna(row['ì‚¬ê³ ê±´ìˆ˜']) else \"ì •ë³´ ì—†ìŒ\"     \n",
    "        result_text = (\n",
    "            f\"ğŸ“ ì—­ëª…: {query}\\n\\n\"\n",
    "            f\"âœ… ì¶”ì²œ ë³´ìˆ˜ ì¡°ì¹˜:\\n{result['ì¶”ì²œ ë³´ìˆ˜ ì¡°ì¹˜']}\\n\\n\"\n",
    "            f\"ğŸ“ ì´ìœ :\\n{result['ì¶”ì²œ ì´ìœ ']}\\n\\n\"\n",
    "            f\"ğŸ’¥ ì‚¬ê³  ê±´ìˆ˜(ìµœê·¼ 5ë…„): {acc_cnt}ê±´  (ìˆœìœ„: {acc_rank})\\n\"       \n",
    "            f\"ğŸ“Š ì‚¬ê³  ìœ í˜• ë¹„ìœ¨:\\n{ratio_str}\\n\\n\"\n",
    "            f\"ğŸ™ í‰ê·  ìœ ë™ì¸êµ¬: {pop}\\n\"\n",
    "            f\"ğŸ“ ì—­ ë©´ì (ã¡): {area}\\n\"\n",
    "            f\"ğŸ‘¥ ìœ ë™ì¸êµ¬ ë°€ë„: {density} ëª…/ã¡\\n\"\n",
    "            f\"ğŸ… ìœ ë™ì¸êµ¬ ë°€ë„ ìˆœìœ„: {pop_rank_str}\\n\\n\"\n",
    "            f\"ğŸ§¯ ì†Œí™”ê¸° ìˆ˜: {ext_cnt} (ë°€ë„ {ext_density} ê°œ/ã¡)\\n\"\n",
    "            f\"   ğŸ‘‰ ì†Œí™”ê¸° ë°€ë„ ìˆœìœ„: {ext_rank_str}\\n\\n\"\n",
    "            f\"ğŸ˜· ëŒ€í”¼ë§ˆìŠ¤í¬ ìˆ˜: {mask_cnt} (ì¸êµ¬ë¹„ {mask_ratio} ê°œ/ëª…)\\n\"\n",
    "            f\"   ğŸ‘‰ ë§ˆìŠ¤í¬ ì¸êµ¬ë¹„ ìˆœìœ„: {mask_rank_str}\"\n",
    "        )\n",
    "    else:\n",
    "        result_text = \"í•´ë‹¹ ì—­ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\"\n",
    "\n",
    "    update_output(result_text)\n",
    "\n",
    "\n",
    "\n",
    "metrics = {\n",
    "    \"ìœ ë™ì¸êµ¬ ë°€ë„\": \"ìœ ë™ì¸êµ¬ë°€ë„\",\n",
    "    \"ì†Œí™”ê¸° ë°€ë„\": \"ì†Œí™”ê¸°ë°€ë„\",\n",
    "    \"ë§ˆìŠ¤í¬ ì¸êµ¬ë¹„\": \"ë§ˆìŠ¤í¬ì¸êµ¬ë¹„\",\n",
    "    \"ì‚¬ê³  ê±´ìˆ˜\":   \"ì‚¬ê³ ê±´ìˆ˜\",\n",
    "}\n",
    "\n",
    "def search_rank():\n",
    "    metric_disp = metric_var.get()\n",
    "    metric_col  = metrics[metric_disp]\n",
    "\n",
    "    try:\n",
    "        start = int(rank_from_entry.get()) if rank_from_entry.get() else 1\n",
    "        end   = int(rank_to_entry.get())   if rank_to_entry.get()   else 20\n",
    "    except ValueError:\n",
    "        update_output(\"ìˆœìœ„ ì…ë ¥ì€ ìˆ«ìì—¬ì•¼ í•©ë‹ˆë‹¤.\")\n",
    "        return\n",
    "    if start < 1 or end < start:\n",
    "        update_output(\"ìˆœìœ„ ë²”ìœ„ë¥¼ ì˜¬ë°”ë¥´ê²Œ ì…ë ¥í•˜ì„¸ìš”.\")\n",
    "        return\n",
    "\n",
    "    ranks = summary[metric_col].rank(ascending=False, method='min')\n",
    "    ranked = ranks.to_frame(\"ìˆœìœ„\").join(summary[[metric_col]])\n",
    "    subset = ranked[(ranked[\"ìˆœìœ„\"] >= start) & (ranked[\"ìˆœìœ„\"] <= end)].sort_values(\"ìˆœìœ„\")\n",
    "\n",
    "    if subset.empty:\n",
    "        update_output(\"í•´ë‹¹ êµ¬ê°„ì— ì—­ì´ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        return\n",
    "\n",
    "    text = f\"ğŸ“ˆ {metric_disp} {start}ìœ„ ~ {end}ìœ„:\\n\\n\"\n",
    "    for idx, row in subset.iterrows():\n",
    "        val = f\"{row[metric_col]:.5f}\" if metric_col != \"ì‚¬ê³ ê±´ìˆ˜\" else f\"{int(row[metric_col])}\"\n",
    "        text += f\"{int(row['ìˆœìœ„'])}ìœ„  {idx}: {val}\\n\"\n",
    "    update_output(text)\n",
    "\n",
    "# -------------------- Tkinter GUI --------------------\n",
    "root = tk.Tk()\n",
    "root.title(\"ì§€í•˜ì² ì—­ ë³´ìˆ˜ ì¶”ì²œ ì‹œìŠ¤í…œ\")\n",
    "root.geometry(\"750x750\")\n",
    "root.option_add(\"*Font\", \"Helvetica 11\")\n",
    "\n",
    "style = ttk.Style(root)\n",
    "style.configure(\"TButton\", padding=6)   \n",
    "\n",
    "# ê²€ìƒ‰ ì„¹ì…˜\n",
    "search_frame = ttk.Frame(root, padding=(10, 15))\n",
    "search_frame.pack(fill=\"x\")\n",
    "\n",
    "ttk.Label(search_frame, text=\"ì§€í•˜ì² ì—­ ê²€ìƒ‰:\", font=(\"Helvetica\", 12, \"bold\")).pack(anchor=\"w\")\n",
    "entry = ttk.Combobox(search_frame, font=(\"Helvetica\", 14), width=30, values=station_names)\n",
    "entry.pack(pady=4)\n",
    "\n",
    "button_frame = ttk.Frame(search_frame)\n",
    "button_frame.pack(pady=4, fill=\"x\")\n",
    "ttk.Button(button_frame, text=\"ê²€ìƒ‰\", command=search_station).pack(side=\"left\", padx=2)\n",
    "\n",
    "# ------------------------ ê°€ëŠ¥í•œ ê²€ìƒ‰ ë²”ìœ„ ------------------------\n",
    "rankable_info = {\n",
    "    \"ìœ ë™ì¸êµ¬ ë°€ë„\": 229,\n",
    "    \"ì†Œí™”ê¸° ë°€ë„\": 225,\n",
    "    \"ë§ˆìŠ¤í¬ ì¸êµ¬ë¹„\": 211,\n",
    "    \"ì‚¬ê³  ê±´ìˆ˜\": 229\n",
    "}\n",
    "\n",
    "desc_text = (\n",
    "    \"â‘  ì§€í‘œë¥¼ ì„ íƒí•˜ê³  â‘¡ ì‹œì‘Â·ë ìˆœìœ„ë¥¼ ì…ë ¥í•œ ë’¤ â‘¢ [ìˆœìœ„ ê²€ìƒ‰]ì„ ëˆ„ë¥´ì„¸ìš”.\\n\\n\"\n",
    "    \"ğŸ“Œ [ê²€ìƒ‰ ê°€ëŠ¥ ìˆœìœ„ ë²”ìœ„]\\n\" +\n",
    "    \"\\n\".join(f\"Â· {k}: 1ìœ„ ~ {v}ìœ„\" for k, v in rankable_info.items())\n",
    ")\n",
    "# -----------------------------------------------------------------\n",
    "\n",
    "# ---------- ìˆœìœ„ ë²”ìœ„ ê²€ìƒ‰ ìœ„ì ¯ ----------\n",
    "rank_frame = ttk.Labelframe(root, text=\"ìˆœìœ„ ë²”ìœ„ ê²€ìƒ‰\", padding=(10, 10))\n",
    "rank_frame.pack(fill=\"x\", padx=10, pady=8)\n",
    "\n",
    "desc_lbl = ttk.Label(rank_frame, text=desc_text, wraplength=700, foreground=\"#444\", justify=\"left\")\n",
    "\n",
    "desc_lbl.pack(anchor=\"w\", pady=2)\n",
    "\n",
    "metric_var = tk.StringVar(value=\"ìœ ë™ì¸êµ¬ ë°€ë„\")\n",
    "metric_menu = ttk.Combobox(rank_frame, textvariable=metric_var,\n",
    "                           values=list(metrics.keys()), state=\"readonly\", width=18)\n",
    "metric_menu.pack(pady=2, anchor=\"w\")\n",
    "\n",
    "range_inner = ttk.Frame(rank_frame)\n",
    "range_inner.pack(pady=2, anchor=\"w\")\n",
    "ttk.Label(range_inner, text=\"ì‹œì‘:\").pack(side=\"left\", padx=(0,2))\n",
    "rank_from_entry = ttk.Entry(range_inner, width=6)\n",
    "rank_from_entry.pack(side=\"left\")\n",
    "ttk.Label(range_inner, text=\"ë:\").pack(side=\"left\", padx=(8,2))\n",
    "rank_to_entry = ttk.Entry(range_inner, width=6)\n",
    "rank_to_entry.pack(side=\"left\", padx=(0,6))\n",
    "\n",
    "ttk.Button(rank_frame, text=\"ìˆœìœ„ ê²€ìƒ‰\", command=search_rank).pack(pady=6)\n",
    "\n",
    "# ---------------- ê²°ê³¼ ì¶œë ¥ì°½ ----------------\n",
    "output_frame = ttk.Frame(root, padding=(10, 5))\n",
    "output_frame.pack(fill=\"both\", expand=True, padx=10, pady=(0,10))\n",
    "\n",
    "output_text = ScrolledText(output_frame, wrap=\"word\", font=(\"Courier New\", 11),\n",
    "                           height=22, state=\"disabled\")\n",
    "output_text.pack(fill=\"both\", expand=True)\n",
    "\n",
    "root.mainloop()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
